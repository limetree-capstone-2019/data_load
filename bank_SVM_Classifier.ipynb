{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this file as reference to build an SVM model for classification. The functions in here are generic and can be used across datasets. The description of each function is given as a doc string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import string\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below block of code uses the training features and labels to fit a svm classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_classifier(train_features, train_labels, kernel=\"linear\"):\n",
    "    \"\"\"learns a classifier from the input features and labels using a specified kernel function\n",
    "\n",
    "    args:\n",
    "        train_features: scipy.sparse.csr.csr_matrix -- sparse matrix of features\n",
    "        train_labels : numpy.ndarray(bool): binary vector of class labels\n",
    "        kernel : str -- kernel function to be used with classifier, must be (linear|poly|rbf|sigmoid)\n",
    "\n",
    "    return : sklearn.svm.classes.SVC -- classifier\n",
    "    \"\"\"\n",
    "    classifier=SVC(kernel = kernel, gamma='auto')\n",
    "    model= classifier.fit(train_features,train_labels)\n",
    "\n",
    "    assert kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(pred, ground):\n",
    "    \"\"\" evaluates a classifier based on a supplied validation data\n",
    "\n",
    "    args:\n",
    "        pred: numpy.ndarray(bool) -- predictions\n",
    "        ground: numpy.ndarray(bool) -- known ground-truth values\n",
    "    \n",
    "    return : double -- the F1 score of the predictions\n",
    "    \"\"\"\n",
    "    pred = np.array(pred, dtype=bool)\n",
    "    ground = np.array(ground, dtype=bool)\n",
    "\n",
    "    return f1_score(ground,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_accuracy(test_labels,pred_labels):\n",
    "    # create confusion matrix\n",
    "    matrix = confusion_matrix(test_labels, pred_test)\n",
    "    accuracy = accuracy_score(test_labels, pred_labels)\n",
    "    # print the accuracy score on the test data\n",
    "    print('Accuracy Score :',accuracy)\n",
    "    return matrix,accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_features, train_labels, kernel=\"linear\"):\n",
    "    \"\"\"train the classifier and report the F1 score on the training set\n",
    "    \n",
    "    args:\n",
    "        train_features: scipy.sparse.csr.csr_matrix -- sparse matrix of features\n",
    "        train_labels : numpy.ndarray(bool): binary vector of class labels\n",
    "        kernel : str -- kernel function to be used with classifier, must be (linear|poly|rbf|sigmoid)\n",
    "\n",
    "    return : double -- the F1 score of the predictions on the training labels\n",
    "    \"\"\"\n",
    "    model = Train_classifier(train_features,train_labels)\n",
    "    preds = model.predict(train_features)\n",
    "    \n",
    "    return preds, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_read_clean(filename):\n",
    "    dataset_directory = \"D:\\\\Coursework\\\\Capstone\\\\clean_repo\\\\data_load\\\\dataset\"\n",
    "    bank_vs_demo = pd.read_csv(dataset_directory+\"\\\\\"+filename)\n",
    "    # drop year, state, zip\n",
    "    bank_vs_demo = bank_vs_demo.drop(['index','year','state','zip','bank_open','bank_close',\n",
    "                                                                'bank_net'], axis=1)\n",
    "    data_list = bank_vs_demo.drop('ground_truth', axis=1)\n",
    "    label_list = bank_vs_demo['ground_truth'] \n",
    "    #Create train and test data. test_size 0.3 means 30% of data will be test data.\n",
    "    #change dataframe to matrix - data_list and label-list\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(data_list.as_matrix(), label_list.as_matrix(), test_size=0.3, random_state=None )\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"<data_set_file_name>\"\n",
    "train_features, test_features, train_labels, test_labels = file_read_clean(filename)\n",
    "train_preds, model = evaluate(train_features, train_labels, \"linear\")\n",
    "test_preds = model.predict(test_features)\n",
    "test_f1_score = f1(test_preds, test_labels)\n",
    "matrix,accuracy = confusion_matrix_accuracy(test_labels,test_preds)\n",
    "\n",
    "# create label\n",
    "labels = ['Open','Constant','Close']\n",
    "\n",
    "# display the heatmap of confusion matrix on the test data\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) \n",
    "ax.set_title('Confusion Matrix - Test Data')\n",
    "sns.heatmap(matrix, annot =True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('Groundtruth')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
